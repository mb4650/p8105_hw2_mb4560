---
title: "Homework 2"
author: Maya Bunyan
output: github_document
---

This is my solution to Homework 2! 

```{r load_packages}
library(tidyverse)
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

```{r}
trashwheel_df = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read and clean 2017 and 2018 precipitation data.

```{r}
precip_2018 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1,
    ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

precip_2017 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1,
    ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

Now combine annual precipitation.

```{r}
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017) 

precip_final = 
  left_join(precip_df, month_df, by = "month")
```


This dataset includes data collected by Mr. Trash Wheel, a water-wheel trash collector, in Baltimore, Maryland. Mr. Trash Wheel collects trash that flows into the inner harbor and then stores that trash in a dumpster, which is later taken to waste-to-energy plants and incinerated to create electricity. The dataset itself includes information on the date, dumpster number, as well as the amount and type of trash. There are `r nrow(trashwheel_df)` observations in our final dataset. We also saw a median number of  `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()` sports balls in a dumpster in 2017. Other sheets include information on the precipitation levels in inches by month. In the combined 2017 and 2018 precipitation dataframe, there are `r nrow(precip_final)` observations, with a total precipitation level of `r precip_final %>% filter(year == 2018) %>% pull(total) %>% sum()` inches in 2018 and `r precip_final %>% filter(year == 2017) %>% pull(total) %>% sum()` inches in 2017.


## Problem 2

Read and clean NYC Transit data.

```{r}
transit_df = 
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_and_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line:entry, vending, ada) %>%
  mutate(
    entry = recode(entry, "YES" = T, "NO" = F)
  )
```

The overall NYC Transit dataset includes information on the various subway stations in NYC, such as station location, routes, entrance and exit information, presence of vending, as well as ADA compliance. In reading in this dataset, I retained specified columns and cleaned the column names using the janitor package and function clean_names. As another step in cleaning the data, I changed the variable entry from a character variable to a logical variable by using the function recode. The resulting data set has `r nrow(transit_df)` rows and `r ncol(transit_df)` columns. The data is not tidy since the routes are spread across multiple columns.


1) There are `r distinct(transit_df, line, station_name) %>% count()` distinct stations in this dataset.
2) `r filter(transit_df, ada == T) %>% distinct(line, station_name) %>% count()` distinct stations are ADA compliant.
3) The proportion of station entrances/exits without vending that allow entrance is `r (filter(transit_df, vending == "NO" & entry == T) %>% count()) / (filter(transit_df, vending == "NO") %>% count())`.


Reformat/tidy the data to make route number and name distinct variables.

```{r}
transit_ref = 
  mutate(
    transit_df,
    route1 = as.character(route1),
    route2 = as.character(route2),
    route3 = as.character(route3),
    route4 = as.character(route4),
    route5 = as.character(route5),
    route6 = as.character(route6),
    route7 = as.character(route7),
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)
  )%>%
  pivot_longer(
      route1:route11,
      names_to = "route_number",
      names_prefix = "route",
      values_to = "route_name"
    ) %>%
  distinct(line, station_name, .keep_all = T) %>%
  drop_na(route_name)
```

There are `r filter(transit_ref, route_name == "A") %>% count()` distinct stations that serve the A train. Of the stations that serve the A train, there are `r filter(transit_ref, route_name == "A" & ada == T) %>% count()` stations that are ADA compliant.


## Problem 3

Read and clean pols-month dataset. Use the month_df dataframe to add month names to dataset.

```{r}
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

pols_mon = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>%
  separate(
    col = mon, 
    into = c("year", "month", "day"),
    convert = TRUE) %>%
  mutate(
    president = if_else(prez_dem == 1, "dem", "gop")
  ) %>%
  select(-prez_gop, -prez_dem, -day)

pols = 
  left_join(pols_mon, month_df, by = "month") %>%
  relocate(month_name, .after = year) %>%
  select(-month) %>%
  rename(month = month_name)
```

Read and clean snp dataset, and have year and month be leading columns. Use the month_df dataframe to add month names to dataset.

```{r}
snp_date = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>%
  separate(
    col = date, 
    into = c("month", "day", "year"),
    convert = TRUE) %>%
  select(-day) %>%
  relocate(year)

snp = 
  left_join(snp_date, month_df, by = "month") %>%
  relocate(month_name, .after = year) %>%
  select(-month) %>%
  rename(month = month_name)
```


Read and clean unemployment dataset, and use the month_df dataframe to add month names to dataset. Make sure it can be merged with previous two datasets.

```{r}
unemp = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_pct"
  ) %>%
  mutate(
    month = 
      recode(
        month, "jan" = 1, "feb" = 2, "mar" = 3, "apr" = 4, "may" = 5,"jun" = 6,
        "jul" = 7, "aug" = 8, "sep" = 9, "oct" = 10, "nov" = 11, "dec" = 12)
    )

unemployment = 
  left_join(unemp, month_df, by = "month") %>%
  relocate(month_name, .after = year) %>%
  select(-month) %>%
  rename(month = month_name)
```

Merge snp into pols, and employment into that result.

```{r}
pols_snp = 
  left_join(pols, snp, by = c("year", "month"))

pols_snp_unemp = 
  left_join(pols_snp, unemployment, by = c("year", "month"))
```

These datasets come from the website FiveThirtyEight, which was founded by Nate Silver. The data found on this website allowed people to test out and see what variables and information affect the association between political party and economic success, specifically what should be included or excluded to show that there is a significant association between the two. In the first dataset, pols-month, there are `r nrow(pols)` observations with information regarding the number of government officials based on political party holding office at a given date. The second dataset, snp, contained `r nrow(snp)` observations regarding the date and the closing Standard & Poor stock market index for that date. The final dataset, unemployment, had `r nrow(unemployment)` observations, which detailed the percent of unemployment for a given month during a given year. All three datasets were cleaned by separating the date into distinct month, day, and year columns. Month and year were retained and formatted to be consistent across the three datasets. A new president variable was created in pols dataset, and the umemployment dataset was converted into a "long" format. The final dataset was created by left joining snp into pols, and then unemployment into that result. This final dataset had `r nrow(pols_snp_unemp)` observations and `r ncol(pols_snp_unemp)` columns. It contains information on what party the president belongs to, the number of governors, senators, and representatives for a given party, the closing S&P stock index, and the percent unemployment for each month during the years `r min(pull(pols_snp_unemp, year))` to `r max(pull(pols_snp_unemp, year))`.




