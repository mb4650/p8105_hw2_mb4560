---
title: "Homework 2"
author: Maya Bunyan
output: github_document
---

This is my solution to Homework 2! 

```{r load_packages}
library(tidyverse)
library(readxl)
library(readr)
```

## Problem 1

Read the Mr. Trashwheel dataset.

```{r}
trashwheel_df = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read and clean 2017 and 2018 precipitation data.

```{r}
precip_2018 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1,
    ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

precip_2017 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1,
    ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

Now combine annual precipitation.

```{r}
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017) 

precip_final = 
  left_join(precip_df, month_df, by = "month")
```


```{r, results='hide'}
#Calculate median sports balls for 2017 to include in inline code
trashwheel_2017 = 
  filter(trashwheel_df, year == 2017)
  
sportsballs_2017 =
  median(pull(trashwheel_2017, sports_balls))
```


This dataset includes data collected by Mr. Trash Wheel, a water-wheel trash collector, in Baltimore, Maryland. Mr. Trash Wheel collects trash that flows into the inner harbor and then stores that trash in a dumpster, which is later taken to waste-to-energy plants and incinerated to create electricity. The dataset itself includes information on the date, dumpster number, as well as the amount and type of trash. There are `r nrow(trashwheel_df)` observations in our final dataset. We also saw a median number of  `r sportsballs_2017` sports balls in a dumpster in 2017. Other sheets include information on the precipitation levels in inches by month. In the combined 2017 and 2018 precipitation dataframe, there are `r nrow(precip_final)` observations, with a total precipitation level of `r sum(pull(precip_2018, total))` inches in 2018 and `r sum(pull(precip_2017, total))` inches in 2017.


## Problem 2

Read and clean NYC Transit data.

```{r}
transit_df = 
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_and_Exit_Data.csv",
    col_types = cols_only(
      Line = col_character(),
      'Station Name' = col_character(),	
      'Station Latitude' = col_number(),	
      'Station Longitude' = col_number(),
      Route1 = col_character(),
      Route2 = col_character(),	
      Route3 = col_character(),
      Route4 = col_character(),
      Route5 = col_character(),
      Route6 = col_character(),
      Route7 = col_character(),
      Route8 = col_character(),
      Route9 = col_character(),
      Route10 = col_character(),
      Route11 = col_character(),
      Entry	= col_character(),
      Vending = col_character(),
      'Entrance Type'	= col_character(),
      ADA = col_character()
    )
  ) %>%
  janitor::clean_names() %>%
  mutate(
    entry = recode(entry, "YES" = T, "NO" = F)
  )
```

The overall NYC Transit dataset includes information on the various subway stations in NYC, such as station location, routes, entrance and exit information, presence of vending, as well as ADA compliance. In reading in this dataset, I retained specified columns, defined their column type. I, then, cleaned the column names using the janitor package and function clean_names. As another step in cleaning the data, I changed the variable entry from a character variable to a logical variable by using the function recode. The resulting data set has `r nrow(transit_df)` rows and `r ncol(transit_df)` columns. The data is not tidy since route name and number are spread across multiple columns.

Use data to answer the specified questions about 1) number of distinct stations, 2) number of ADA compliant stations, and 3) proportion of station entrances without vending that allow entrance.

```{r, results='hide'}
distinct_stations = 
  distinct(
    transit_df, 
    station_name, 
    route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11,
    .keep_all = T
    )

ada_compliant = 
  filter(distinct_stations, ada == "TRUE")

no_vending = 
  filter(transit_df, vending == "NO") 
allow_entry = 
  filter(no_vending, entry == T)
vending_entry = 
  nrow(allow_entry)/nrow(no_vending)

```

1) There are `r nrow(distinct_stations)` distinct stations in this dataset.
2) `r nrow(ada_compliant)` distinct stations are ADA compliant.
3) The proportion of station entrances/exits without vending that allow entrance is `r vending_entry`, or `r (vending_entry)*100`%.


Reformat the data to make route number and name distinct variables. Then create variables to be used in inline code to answer specified questions.

```{r}
transit_ref = 
  distinct(
    pivot_longer(
      transit_df,
      route1:route11,
      names_to = "route_number",
      names_prefix = "route",
      values_to = "route_name"
    ),
  station_name, route_number, route_name, .keep_all = T) %>%
  drop_na(route_name)

transit_atrain = 
  filter(transit_ref, route_name == "A")

transit_atrain_ada =
  filter(transit_atrain, ada == "TRUE")
```

There are `r nrow(transit_atrain)` distinct stations that serve the A train. Of the stations that serve the A train, there are `r nrow(transit_atrain_ada)` stations that are ADA compliant.
